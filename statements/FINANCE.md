---
abbr: FINANCE
agency: Department of Finance
source_url: https://www.finance.gov.au/about-us/artificial-intelligence-ai-transparency-statement
title: Artificial Intelligence (AI) Transparency Statement | Department of Finance
---

# Artificial Intelligence (AI) Transparency Statement

The Department of Finance (Finance) is committed to the safe and responsible use of artificial intelligence (AI).

We consider AI offers significant opportunities to improve productivity and service delivery within our workplace.

We govern our AI in line with applicable laws and regulations, the Digital Transformation Agency's (DTA) [Policy for the responsible use of AI in government](https://www.digital.gov.au/policy/ai/policy) (the Policy) and best practice.

## Our approach to AI

At Finance, we are applying the guidance outlined in DTA’s Pilot [Australian Government AI assurance framework ](https://www.digital.gov.au/policy/ai/pilot-ai-assurance-framework)(the Framework) and have chosen to limit our use of AI to low-risk use cases. This guidance implements [Australia’s AI Ethics Principles](https://www.industry.gov.au/publications/australias-artificial-intelligence-ethics-principles/australias-ai-ethics-principles) and uses the [Organisation for Economic Cooperation and Developments (OECD)](https://oecd.ai/en/ai-principles) concepts to define AI and identify which of our systems uses AI.

We assess the risk of each use case against 7 criteria and a risk matrix outlined in [the framework](https://www.digital.gov.au/policy/ai/pilot-ai-assurance-framework). These are:

  * fairness
  * reliability and safety
  * privacy protection and security
  * transparency and explainability
  * contestability
  * accountability
  * human-centered values.

This assessment determines if a use case is low, medium, or high risk. A low-risk use case means AI does not:

  * directly interact with, or significantly impact the public without human intervention
  * risk the security of the information or data we hold
  * harm the privacy of any individual, including our staff.

We reassess our use cases when:

  * a notable change is made to our approach to AI or use of AI
  * a use case progresses to another stage in its life cycle
  * an AI risk or harm is identified with a use case.

Any use case reassessed as being high risk will be reported to the DTA.

## How we use AI

We allow our staff to use AI in their work with the objective of enhancing productivity and service delivery. This includes enterprise AI deployed in our closed internal ICT environment like Microsoft 365 Copilot, as well as publicly available AI like ChatGPT, Claude and Gemini that is that is not deployed in our closed internal ICT environment.

The tasks completed by our staff using AI falls into several usage patterns and domains as outlined by the DTA’s [Classification system for AI use](https://www.digital.gov.au/sites/default/files/documents/2024-08/Standard%20for%20AI%20transparency%20statements%20v1.1.pdf). These are:

  * the _Analytics and insights_ usage pattern primarily in the _Scientific_ , and _Policy and legal_ domains, where the sensitivity of the data is low risk
  * the _Workplace productivity_ usage pattern primarily in the _Service delivery_ , and _Corporate and enabling_ domains.

Our staff use AI to:

  * assist in the creation of accessible versions of government documents,
  * assist with policy research and analysis
  * summarise data across multiple sources
  * interrogate, analyse and obtain insights from datasets
  * answer questions from staff regarding workplace policies, procedures and processes
  * assist in the analysis, creation or summarisation of documents, emails or other content
  * create and debug code used in data analysis, management and processing
  * assist in the creation of meeting minutes or interview transcripts
  * search information repositories and retrieve documents, information or data.

We do not use AI within the _Decision making and administrative action_ or _Image processing_ usage patterns, or the _Compliance and fraud detection_ , and _Law enforcement, intelligence and security_ domains.

## How we govern our AI

Finance has a risk-based approach to the use of AI. This approach focuses on identifying, evaluating and monitoring the level of risk associated with implementing AI systems. Once implemented, we monitor the effectiveness of our AI systems by:

  * having robust governance arrangements, policies and processes; and
  * monitoring AI usage.

### Our AI Governance Committee

We have an AI Governance Committee (the Committee) to oversee our adoption and use of AI within Finance. The functions of this Committee include:

  * developing and implementing AI safely
  * identifying, assessing and managing AI risks and opportunities
  * promoting a culture of safe and responsible use of AI
  * overseeing and implementing policies and advice from the DTA.

This Committee is co-chaired by two accountable officials (AO) and its membership includes senior executive representatives from the following areas: 

  * Information Communication Technology Division (co-chair, First Assistant Secretary, Chief Information Officer and AO)
  * Risk, Claims and Regulatory Reform Division (co-chair, First Assistant Secretary and AO)
  * Budget Policy and Data Division
  * Corporate Strategy and Operations Division
  * Digital ID and Data Policy Division
  * Legal and Assurance Branch
  * Human Resources Branch.

### Our internal policies and processes

Finance has policies and processes for the adoption and use of AI by our staff, including:

  * Acceptable use policy
  * Guidance on the use of generative artificial intelligence
  * Information security management policy framework
  * Information and data policy
  * Privacy policy
  * Risk management policy framework.

These are regularly reviewed to ensure they remain fit for purpose.

We provide our staff with guidance and training on the safe and responsible use of AI. Staff are required to complete this training prior to being granted access to our secure internal AI.

### Our adherence to Whole of Australian Government AI policies

Finance is dedicated to fully implementing [the Policy](https://www.digital.gov.au/policy/ai/policy) and ensuring ongoing compliance with [the Policy.](https://www.digital.gov.au/policy/ai/policy) This includes reviewing and updating this statement annually, or when new factors or significant changes to our AI approach impact it.

Finance has implemented all mandatory requirements outlined within [the Policy](https://www.digital.gov.au/policy/ai/policy), as demonstrated by the information contained within this statement.

## Who to contact regarding our statement

For any questions regarding this statement, or for more information about how Finance uses AI, please email: [feedback@finance.gov.au](mailto:feedback@finance.gov.au)

This statement is authorised by Finance’s two accountable officials, the First Assistant Secretary of the Information, Communication and Technology Division and the First Assistant Secretary of the Risk, Claims and Regulatory Reform Division.  

* * *

Did you find this content useful?

__

__

Your comments (if any)

Page

Submit

Leave this field blank